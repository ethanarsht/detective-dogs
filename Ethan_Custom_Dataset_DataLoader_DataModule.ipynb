{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanarsht/detective-dogs/blob/Ethan/Ethan_Custom_Dataset_DataLoader_DataModule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enSFzSe4VZkU"
      },
      "outputs": [],
      "source": [
        "# Now that you know how to read in images, get their\n",
        "# dimensions and visualize them, let's move on to working on\n",
        "# our PyTorch dataset and COMPLETE THER EST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# our FIRST step before we even get to building PyTorch objects\n",
        "# is actually setting up a csv file that maps the file paths to\n",
        "# their label and their category (i.e. train, val, test)\n",
        "\n",
        "# one thing to consider here is the directory structure of chest_xray.\n",
        "# within the chest_xray dir, there are three directories (train, val, test)\n",
        "# and within those, there are two subdirectories (NORMAL, PNEUMONIA)\n",
        "\n",
        "# scroll down to the __getitem___ part of our custom dataset and think\n",
        "# about how you wanna handle your file paths before you construct your\n",
        "# csv files!\n",
        "\n",
        "# you might want to create 3 csv files (one for train, one for val, one\n",
        "# for test) or you might have to just create 1 mega csv!\n",
        "# totally up to you. Whatever you decide, you will have to adjust\n",
        "# how you initialize your Dataset paramaeter (i.e. do you pass in the \n",
        "# path to the csv file? or a subset of a pandas df?)\n",
        "\n",
        "# i'm gonna let you work some Pandas magic on your own! ;)"
      ],
      "metadata": {
        "id": "3UZeAcRVW9kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, that we got our csv file(s) and our images, we're finally\n",
        "# ready to interact with PyTorch!\n",
        "\n",
        "# At minimum, we'll implement three objects:\n",
        "# - a custom Dataset object (PyTorch object)\n",
        "# - your image transformations (augmentations!)\n",
        "# - a DataLoader\n",
        "\n",
        "# OPTIONAL: you can also implement \n",
        "# - a custom DataModule (PyTorch Lightning object)\n",
        "#     * DataModule will use the DataLoader but the Module will\n",
        "#     * nicely encapsulate other things like data augmentation!\n",
        "#     * it's not a lot of work so I recommend it! It will make your life\n",
        "#     * for checkpoint #2!"
      ],
      "metadata": {
        "id": "BETeCabrYivE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "VW64heyUiHFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in implemting a custom PyTorch dataset you must implement\n",
        "# three methods: __init__, __len__, and __getitem__\n",
        "\n",
        "# a Dataset is indexable, which makes allows you index (duh)\n",
        "# into your dataset, but also gives random access for \n",
        "# shuffling (which you can do yourself, or use a DataLoader, or\n",
        "# use a DataModule)\n",
        "\n",
        "# for more help: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir_path, transform=None):\n",
        "        \"\"\"\n",
        "        You can set your custom dataset to take in more parameters than specified\n",
        "        here. But, I recommend at least you start with the three I listed here,\n",
        "        as these are standard\n",
        "\n",
        "        csv_file (str): file path to the csv file you created /\n",
        "        df (pandas df): pandas dataframe\n",
        "\n",
        "        img_dir_path: directory path to your images\n",
        "        transform: Compose (a PyTorch Class) that strings together several\n",
        "          transform functions (e.g. data augmentation steps)\n",
        "\n",
        "        One thing to note -- you technically could implement `transform` within\n",
        "        the dataset. No one is going to stop you, but you can think of the\n",
        "        transformations/augmentations you do as a hyperparameter. If you treat\n",
        "        it as a hyperparameter, you want to be able to experiment with different\n",
        "        transformations, and therefore, it would make more sense to decide those\n",
        "        transformations outside the dataset class and pass it to the dataset!\n",
        "        \"\"\"\n",
        "        self.img_labels = csv_file\n",
        "        self.img_dir = img_dir_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns: (int) length of your dataset\n",
        "        \"\"\"\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loads and returns your sample (the image and the label) at the\n",
        "        specified index\n",
        "\n",
        "        Parameter: idx (int): index of interest\n",
        "\n",
        "        Returns: image, label\n",
        "        \"\"\"\n",
        "\n",
        "        # think about how you wanna handle the image path\n",
        "        # re: making your own csv files! \n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "IeESUPd2i0Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hld7EoaZXvCY",
        "outputId": "6fba6c74-e78f-4a29-f723-c62f1d198156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dir in ['test', 'train', 'val']:\n",
        "  paths = []\n",
        "  labels = []\n",
        "  folders = os.listdir('drive/MyDrive/pneumonia_images/' + dir)\n",
        "  for f in folders:\n",
        "    paths = os.listdir('drive/MyDrive/pneumonia_images/' + dir + '/' + f)\n",
        "    label = f\n",
        "\n",
        "  dir_csv = pd.DataFrame(\n",
        "      dict(path = paths,\n",
        "      label = label)\n",
        "  )\n",
        "  dir_csv.to_csv('drive/MyDrive/pneumonia_images/' + dir + '/' + dir + '.csv')"
      ],
      "metadata": {
        "id": "uGLxEXNgWDea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing your transformations\n",
        "\n",
        "# for additional help: https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose\n",
        "\n",
        "# for a list of transformations illustrated: \n",
        "# https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "\n",
        "# NOTE: per PyTorch, \n",
        "\"\"\"\n",
        "Most transformations accept both PIL images and tensor images,\n",
        "although some transformations are PIL-only and some are tensor-only.\n",
        "\"\"\"\n",
        "\n",
        "# therefore, you will have to experiment with what works with your image!\n",
        "# or read the documentation!\n",
        "\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transforms = T.Compose(\n",
        "    [\n",
        "        # if you are using cv2, you will need to FIRST convert\n",
        "        # the image to a Tensor. if you are using PIL to read in your image\n",
        "        # you will need to convert uit to a Tensor eventually!\n",
        "     \n",
        "        T.RandomAdjustSharpness(sharpness_factor=2),\n",
        "        T.RandomPosterize(bits=4, p=0.5)\n",
        "        # this is just an example. I randomly selected some.\n",
        "        # Choose your own more carefully! :)\n",
        "        # you will definitely want to RESIZE your image! if you don't want to\n",
        "        # decide on a size yet, you can return to resizing for checkpoint #2 when\n",
        "        # we implement our custom model!\n",
        "\n",
        "        # if you are normalizing your image, you will need to consider two things\n",
        "     \n",
        "        # 1) if you are using a pre-trained model, you will use the mean and SD\n",
        "        # of the data that model was trained on\n",
        "        # (this does not apply to us yet or ever, depending on what you do for the\n",
        "        # final part of the project)\n",
        "\n",
        "        # 2) if you are using a custom model, you will need to normalize your images\n",
        "        # based on the mean and SD of your TRAINING data\n",
        "        # and you will have to normalize your validation and your test data, too\n",
        "        # using your training data's mean and SD\n",
        "     \n",
        "        # this brings us to another good point to consider -- you might have to\n",
        "        # prepare two transformations for your datasets \n",
        "        # your augmentation transform for your training data, which will normalize\n",
        "        # (if you're doing that), distort and resize the image\n",
        "        # one that just normalizes (if you're doing that) and resizes\n",
        "        # your validation and testing data\n",
        "     \n",
        "        # LOTS TO THINK ABOUT <3 \n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "RbpNQLXl1Hx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building your DataLoaders\n",
        "\n",
        "# here we can more directly see how the dataset interacts wiht the dataloader\n",
        "# the dataloader really is just an iterator. it's not very \"smart\"\n",
        "# it's not going to give you validation data just because you named it val_dataloader\n",
        "# so the distinction will need to happen when you create val_data, which means that\n",
        "# you need to either build in an mechanism internally in the CustomImageDataset to \n",
        "# parse for `valid` category inside the csv (if you are just providing the file path\n",
        "# to a mega csv) or you can pass it an already subsetted csv or df!\n",
        "\n",
        "training_data = CustomImageDataset('drive/MyDrive/pneumonia_images/train/train.csv', \n",
        "                                   'drive/MyDrive/pneumonia_images/train/NORMAL', \n",
        "                                   transforms)\n",
        "#val_data = CustomImageDataset('drive/MyDrive/pneumonia_images/', img_dir_path, transforms)\n",
        "#test_data = CustomImageDataset('drive/MyDrive/pneumonia_images/', img_dir_path, transforms)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "FfG3Zebe9k3n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "7f7e508c-8be4-4787-c0a0-43c76199536a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8bde5241b593>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader"
      ],
      "metadata": {
        "id": "ZfVf5PsFDrAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011efc9e-c228-4851-f2b3-ba2e6e0d2fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f431ba5a7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqDgys7pyfkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}